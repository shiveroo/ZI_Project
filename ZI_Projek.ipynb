{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZI_Projekt\n",
    "* Marcin Mikołajczak\n",
    "* Adam Pertek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temat projektu: kategoryzjacja flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projekt ma na celu kategoryzację flag różnych państw.\n",
    "Został wykonany z wykorzystaniem języka python i biblioteki tensorflow.\n",
    "Projekt oparty został na \"transfer learning\", czyli metodzie uczenia maszynowego, w której wykorzystywany jest model wcześniej wytrenowany dla innego zadania i wykorzystywany jest jako punkt wyjścia w nowym zadaniu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Struktura projektu:\n",
    "* training_images\n",
    "    + category_1\n",
    "    + category_2\n",
    "    + catgory_x\n",
    "    \n",
    "* test_images\n",
    "\n",
    "* train.py\n",
    "* test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folder \"train_images\" zawiera podfoldery, w których zawierają się obrazy wykorzystywane podczas procesu uczenia i walidacji.\n",
    "Na podstawie nazw tych folderów tworzone są kategorie, do których przyporządkowywane są następnie obrazy. W przypadku tego projektu folderu te mają nazwy:\n",
    "- poland_flag\n",
    "- ukraine flag\n",
    "- uk_flag\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jako zbiór na podstawie, którego uczona jest sieć neuronowa zebrano flagi 19 państw. Wybrane zostały głównie duże kraje, dla których możliwie łatwe było zebranie obrazów testowych. Dla każego z pańsw zebrano ok. 120 obrazów, należą do nich: Austria, Belgia, Kanada, Finlandia, Francja, Niemcy, Grecja, Irlandia, Litwa, Holandia, Polska, Portugalia, Rosja, Serbia, Hiszpania, Szwecja, Uk, Ukraina oraz USA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projekt został podzielony na dwa pliki: train.py oraz test.py.\n",
    "Pierwszy z nich służy do pobrania modelu, który użyty będzie w \"transfer learningu\", ustawienia parametrów uczenia oraz sprawdzenie poprawności folderów i danych wejściowych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File: train.py\n",
    "Początek programu to importowanie niezbędnych bibliotek a także ustawienie wartości zmiennych, służących za parametry konfiguracyjne projeku takie jak: minimalna liczba obrazów w każdej kategori niezbędna do rozpoczęcia procesu trenowania, maksymalna liczba obrazów, miejsca zapisu i nazwy dla grafów modelu, procent obrazów, który użyty zostanie jako dane walidacyjne i testowe oraz nazwę architektury, która zostanie pobrana przy pierwszym uruchomieniu programu.\n",
    "Użyty zostanie tutaj model inception_v3. Jest to architektura najdokładniejsza, trenowana na największej liczbie kategorii, lecz najwolniejsza. Na potrzeby tego projektu sprawdzi się idealni, gdyż liczba kategorii, do których klasyfikowane są obrazy nie jest duża."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import hashlib\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib.quantize.python import quant_ops\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.util import compat\n",
    "\n",
    "# zmienne określające wymagania dot danych wejściowych\n",
    "MIN_NUM_IMAGES_REQUIRED_FOR_TRAINING = 10\n",
    "MIN_NUM_IMAGES_SUGGESTED_FOR_TRAINING = 100\n",
    "\n",
    "MIN_NUM_IMAGES_REQUIRED_FOR_TESTING = 3\n",
    "\n",
    "MAX_NUM_IMAGES_PER_CLASS = 2 ** 27 - 1  # ~134M\n",
    "\n",
    "# sciezka do folderow z obrazami\n",
    "TRAINING_IMAGES_DIR = os.getcwd() + '/training_images'\n",
    "TEST_IMAGES_DIR = os.getcwd() + \"/test_images/\"\n",
    "\n",
    "# miejsce zapisania grafow, ich plikow i logow\n",
    "OUTPUT_GRAPH = os.getcwd() + '/' + 'retrained_graph.pb'\n",
    "TENSORBOARD_DIR = os.getcwd() + '/' + 'tensorboard_logs'\n",
    "OUTPUT_LABELS = os.getcwd() + '/' + 'retrained_labels.txt'\n",
    "\n",
    "# ilosc krokow treninogwych (rekomendowana 8000 lub wiecej)\n",
    "HOW_MANY_TRAINING_STEPS=8000\n",
    "\n",
    "# rozmiar wskaznika do uczenia\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "# procent obrazow uzytych jako dane testowe i walidacyjne (optimum podobno 10-20%)\n",
    "TESTING_PERCENTAGE = 10\n",
    "VALIDATION_PERCENTAGE = 10\n",
    "\n",
    "# co ile krokow ewaluowac model\n",
    "EVAL_STEP_INTERVAL = 10\n",
    "\n",
    "# ile obrazow cwiczyc na raz\n",
    "TRAIN_BATCH_SIZE = 100\n",
    "\n",
    "TEST_BATCH_SIZE = -1\n",
    "\n",
    "VALIDATION_BATCH_SIZE = 100\n",
    "\n",
    "# czy drukowac blednie sklasyfikowane obrazu\n",
    "PRINT_MISCLASSIFIED_TEST_IMAGES = False\n",
    "\n",
    "#sciezka do modelu z grafem\n",
    "MODEL_DIR = os.getcwd() + \"/\" + \"model\"\n",
    "\n",
    "# Path to cache bottleneck layer values as files\n",
    "BOTTLENECK_DIR = os.getcwd() + '/' + 'bottleneck_data'\n",
    "\n",
    "# nazwa wyjsciowej warstwy klasyfikacji w grafie\n",
    "FINAL_TENSOR_NAME = 'final_result'\n",
    "\n",
    "ARCHITECTURE = 'inception_v3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja main()\n",
    "Jest główną funkcją, w której wykonywane są kolejno: ustawienie widoczności logów tensorflow, sprawdzanie wszystkich niezbędnych ścieżek (do obrazów treninogwych i testowych), pobranie modelu na podstawie określonej wyżej architektury (model pobierany jest tylko jeśli nie istnieje w ścieżce projektu), tworzenie grafu oraz tworzenie listy zdjęć dla wczytanych kategorii.\n",
    "Następnie dodawana jest warstwa softmax i następuje proces uczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"starting program . . .\")\n",
    "    # ustawienie widocznosci logow\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    if not checkIfNecessaryPathsAndFilesExist():\n",
    "        return\n",
    "\n",
    "    # wczytywanie informacji o architekturze modelu\n",
    "    model_info = create_model_info(ARCHITECTURE)\n",
    "    if not model_info:\n",
    "        tf.logging.error('Did not recognize architecture flag')\n",
    "        return -1\n",
    "\n",
    "    #pobranie modelu i utworzenie grafu modelu\n",
    "    print(\"downloading model (if necessary) . . .\")\n",
    "    downloadModelIfNotAlreadyPresent(model_info['data_url'])\n",
    "    print(\"creating model graph . . .\")\n",
    "    graph, bottleneck_tensor, resized_image_tensor = (create_model_graph(model_info))\n",
    "\n",
    "    # utworzenie listy zdjec\n",
    "    print(\"creating image lists . . .\")\n",
    "    image_lists = create_image_lists(TRAINING_IMAGES_DIR, TESTING_PERCENTAGE, VALIDATION_PERCENTAGE)\n",
    "    class_count = len(image_lists.keys())\n",
    "    if class_count == 0:\n",
    "        tf.logging.error('No valid folders of images found at ' + TRAINING_IMAGES_DIR)\n",
    "        return -1\n",
    "    if class_count == 1:\n",
    "        tf.logging.error('Only one valid folder of images found at ' + TRAINING_IMAGES_DIR + ' - multiple classes are needed for classification.')\n",
    "        return -1\n",
    "\n",
    "    print(\"starting session . . .\")\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        print(\"performing jpeg decoding . . .\")\n",
    "        jpeg_data_tensor, decoded_image_tensor = add_jpeg_decoding( model_info['input_width'],\n",
    "                                                                    model_info['input_height'],\n",
    "                                                                    model_info['input_depth'],\n",
    "                                                                    model_info['input_mean'],\n",
    "                                                                    model_info['input_std'])\n",
    "        print(\"caching bottlenecks . . .\")\n",
    "\n",
    "        cache_bottlenecks(sess, image_lists, TRAINING_IMAGES_DIR, BOTTLENECK_DIR, jpeg_data_tensor, decoded_image_tensor,\n",
    "                              resized_image_tensor, bottleneck_tensor, ARCHITECTURE)\n",
    "\n",
    "        # Dodanie nowej warstwy\n",
    "        print(\"adding final training layer . . .\")\n",
    "        (train_step, cross_entropy, bottleneck_input, ground_truth_input, final_tensor) = add_final_training_ops(len(image_lists.keys()),\n",
    "                                                                                                                 FINAL_TENSOR_NAME,\n",
    "                                                                                                                 bottleneck_tensor,\n",
    "                                                                                                                 model_info['bottleneck_tensor_size'],\n",
    "                                                                                                                 model_info['quantize_layer'])\n",
    "        # operacja potrzebna do zmiany dokladnosci nowej warstwy\n",
    "        print(\"adding eval ops for final training layer . . .\")\n",
    "        evaluation_step, prediction = add_evaluation_step(final_tensor, ground_truth_input)\n",
    "\n",
    "        # zebranie wszystki danych i zapisanie do tensorboard dir\n",
    "        print(\"writing TensorBoard info . . .\")\n",
    "        merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter(TENSORBOARD_DIR + '/train', sess.graph)\n",
    "        validation_writer = tf.summary.FileWriter(TENSORBOARD_DIR + '/validation')\n",
    "\n",
    "        # ustawienie wag do domyslnych wartosci\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        #rozpoczecie uczenia\n",
    "        print(\"performing training . . .\")\n",
    "        for i in range(HOW_MANY_TRAINING_STEPS):\n",
    "            (train_bottlenecks, train_ground_truth, _) = get_random_cached_bottlenecks(sess, image_lists, TRAIN_BATCH_SIZE, 'training',\n",
    "                                                                                           BOTTLENECK_DIR, TRAINING_IMAGES_DIR, jpeg_data_tensor,\n",
    "                                                                                           decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n",
    "                                                                                           ARCHITECTURE)\n",
    "\n",
    "            # Rozpoczęcie uczenia, \n",
    "            train_summary, _ = sess.run([merged, train_step], feed_dict={bottleneck_input: train_bottlenecks, ground_truth_input: train_ground_truth})\n",
    "            train_writer.add_summary(train_summary, i)\n",
    "\n",
    "            # Wyswietlanie wskaznikow uczenia sie.\n",
    "            is_last_step = (i + 1 == HOW_MANY_TRAINING_STEPS)\n",
    "            if (i % EVAL_STEP_INTERVAL) == 0 or is_last_step:\n",
    "                train_accuracy, cross_entropy_value = sess.run([evaluation_step, cross_entropy], feed_dict={bottleneck_input: train_bottlenecks, ground_truth_input: train_ground_truth})\n",
    "                tf.logging.info('%s: Step %d: Train accuracy = %.1f%%' % (datetime.now(), i, train_accuracy * 100))\n",
    "                tf.logging.info('%s: Step %d: Cross entropy = %f' % (datetime.now(), i, cross_entropy_value))\n",
    "                validation_bottlenecks, validation_ground_truth, _ = (get_random_cached_bottlenecks(sess, image_lists, VALIDATION_BATCH_SIZE, 'validation',\n",
    "                                                                                                    BOTTLENECK_DIR, TRAINING_IMAGES_DIR, jpeg_data_tensor,\n",
    "                                                                                                    decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n",
    "                                                                                                    ARCHITECTURE))\n",
    "                # Rozpoczecie walidacji.\n",
    "                validation_summary, validation_accuracy = sess.run(\n",
    "                    [merged, evaluation_step], feed_dict={bottleneck_input: validation_bottlenecks, ground_truth_input: validation_ground_truth})\n",
    "                validation_writer.add_summary(validation_summary, i)\n",
    "                tf.logging.info('%s: Step %d: Validation accuracy = %.1f%% (N=%d)' % (datetime.now(), i, validation_accuracy * 100, len(validation_bottlenecks)))\n",
    "\n",
    "        # Koncowa ewaluacja na nieuzywanych jeszcze obrazach\n",
    "        print(\"running testing . . .\")\n",
    "        test_bottlenecks, test_ground_truth, test_filenames = (get_random_cached_bottlenecks(sess, image_lists, TEST_BATCH_SIZE, 'testing', BOTTLENECK_DIR,\n",
    "                                                                                             TRAINING_IMAGES_DIR, jpeg_data_tensor, decoded_image_tensor, resized_image_tensor,\n",
    "                                                                                             bottleneck_tensor, ARCHITECTURE))\n",
    "        test_accuracy, predictions = sess.run([evaluation_step, prediction], feed_dict={bottleneck_input: test_bottlenecks, ground_truth_input: test_ground_truth})\n",
    "        tf.logging.info('Final test accuracy = %.1f%% (N=%d)' % (test_accuracy * 100, len(test_bottlenecks)))\n",
    "\n",
    "        if PRINT_MISCLASSIFIED_TEST_IMAGES:\n",
    "            tf.logging.info('=== MISCLASSIFIED TEST IMAGES ===')\n",
    "            for i, test_filename in enumerate(test_filenames):\n",
    "                if predictions[i] != test_ground_truth[i]:\n",
    "                    tf.logging.info('%70s  %s' % (test_filename, list(image_lists.keys())[predictions[i]]))\n",
    "\n",
    "        # wypisanie wag klasyfikatora\n",
    "        print(\"writing trained graph and labbels with weights\")\n",
    "        save_graph_to_file(sess, graph, OUTPUT_GRAPH)\n",
    "        with gfile.FastGFile(OUTPUT_LABELS, 'w') as f:\n",
    "            f.write('\\n'.join(image_lists.keys()) + '\\n')\n",
    "\n",
    "        print(\"done !!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja checkIfNecessaryPathsAndFilesExist()\n",
    "Funckja sprawdza czy istnieją foldery obrazów testowych i treningowych. Czy znajduje się w nich minimalna wymagana liczba obrazów oraz czy mają one odpowiedni format. W programie akceptowane są pliki .jgp. Jeśli któryś z tych warunków nie jest spełniony funkcja zwraca błąd a program zostaje przerwany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIfNecessaryPathsAndFilesExist():\n",
    "    if not os.path.exists(TRAINING_IMAGES_DIR):\n",
    "        print('')\n",
    "        print('ERROR: TRAINING_IMAGES_DIR \"' + TRAINING_IMAGES_DIR + '\" does not seem to exist')\n",
    "        print('Did you set up the training images?')\n",
    "        print('')\n",
    "        return False\n",
    "\n",
    "    class TrainingSubDir:\n",
    "        def __init__(self):\n",
    "            self.loc = \"\"\n",
    "            self.numImages = 0\n",
    "\n",
    "    # lista sub-folderow\n",
    "    trainingSubDirs = []\n",
    "\n",
    "    for dirName in os.listdir(TRAINING_IMAGES_DIR):\n",
    "        currentTrainingImagesSubDir = os.path.join(TRAINING_IMAGES_DIR, dirName)\n",
    "        if os.path.isdir(currentTrainingImagesSubDir):\n",
    "            trainingSubDir = TrainingSubDir()\n",
    "            trainingSubDir.loc = currentTrainingImagesSubDir\n",
    "            trainingSubDirs.append(trainingSubDir)\n",
    "\n",
    "    #komunikatu bledu jesli zla struktura folderow\n",
    "    if len(trainingSubDirs) == 0:\n",
    "        print(\"ERROR: there don't seem to be any training image sub-directories in \" + TRAINING_IMAGES_DIR)\n",
    "        print(\"Did you make a separare image sub-directory for each classification type?\")\n",
    "        return False\n",
    "\n",
    "    # przypisanie liczby obrazow dla kazdej sub-kategori\n",
    "    for trainingSubDir in trainingSubDirs:\n",
    "        for fileName in os.listdir(trainingSubDir.loc):\n",
    "            if fileName.endswith(\".jpg\"):\n",
    "                trainingSubDir.numImages += 1\n",
    "\n",
    "    #sprawdzenie czy jest minimalna liczba wymaganych obrazow\n",
    "    for trainingSubDir in trainingSubDirs:\n",
    "        if trainingSubDir.numImages < MIN_NUM_IMAGES_REQUIRED_FOR_TRAINING:\n",
    "            print(\"ERROR: there are less than the required \" + str(MIN_NUM_IMAGES_REQUIRED_FOR_TRAINING) + \" images in \" + trainingSubDir.loc)\n",
    "            print(\"Did you populate each training sub-directory with images?\")\n",
    "            return False\n",
    "\n",
    "    # sprawdzenie czy spelniona jest liczba rekomendowanej ilosci obrazow\n",
    "    for trainingSubDir in trainingSubDirs:\n",
    "        if trainingSubDir.numImages < MIN_NUM_IMAGES_SUGGESTED_FOR_TRAINING:\n",
    "            print(\"WARNING: there are less than the suggested \" + str(MIN_NUM_IMAGES_SUGGESTED_FOR_TRAINING) + \" images in \" + trainingSubDir.loc)\n",
    "            print(\"More images should be added to this directory for acceptable training results\")\n",
    "\n",
    "    #error jesli sciezka nie istnieje\n",
    "    if not os.path.exists(TEST_IMAGES_DIR):\n",
    "        print('')\n",
    "        print('ERROR: TEST_IMAGES_DIR \"' + TEST_IMAGES_DIR + '\" does not seem to exist')\n",
    "        print('Did you break out some test images?')\n",
    "        print('')\n",
    "        return False\n",
    "\n",
    "    numImagesInTestDir = 0\n",
    "    for fileName in os.listdir(TEST_IMAGES_DIR):\n",
    "        if fileName.endswith(\".jpg\"):\n",
    "            numImagesInTestDir += 1\n",
    "\n",
    "    # czy jest min liczba obrazow w testowej sciezce\n",
    "    if numImagesInTestDir < MIN_NUM_IMAGES_REQUIRED_FOR_TESTING:\n",
    "        print(\"ERROR: there are not at least \" + str(MIN_NUM_IMAGES_REQUIRED_FOR_TESTING) + \" images in \" + TEST_IMAGES_DIR)\n",
    "        print(\"Did you break out some test images?\")\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja makeDirIfDoesNotExist()\n",
    "Tworzy ona folder jeśli ten istnieje w danej ścieżce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDirIfDoesNotExist(dir_name):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja create_model_info()\n",
    "Funkcja określa parametry modelu i zwraca informacje na jego temat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_info(architecture):\n",
    "    \"\"\"\n",
    "    Zwraca informacje na temat modelu\n",
    "    \"\"\"\n",
    "    architecture = architecture.lower()\n",
    "    if architecture == 'inception_v3':\n",
    "        # pylint: disable=line-too-long\n",
    "        data_url = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n",
    "        # pylint: enable=line-too-long\n",
    "        bottleneck_tensor_name = 'pool_3/_reshape:0'\n",
    "        bottleneck_tensor_size = 2048\n",
    "        input_width = 299\n",
    "        input_height = 299\n",
    "        input_depth = 3\n",
    "        resized_input_tensor_name = 'Mul:0'\n",
    "        model_file_name = 'classify_image_graph_def.pb'\n",
    "        input_mean = 128\n",
    "        input_std = 128\n",
    "\n",
    "        data_url = 'http://download.tensorflow.org/models/mobilenet_v1_'\n",
    "        data_url += version_string + '_' + size_string + '_frozen.tgz'\n",
    "        bottleneck_tensor_name = 'MobilenetV1/Predictions/Reshape:0'\n",
    "        resized_input_tensor_name = 'input:0'\n",
    "        model_dir_name = 'mobilenet_v1_' + version_string + '_' + size_string\n",
    "        model_base_name = 'frozen_graph.pb'\n",
    "        # end if\n",
    "\n",
    "        bottleneck_tensor_size = 1001\n",
    "        input_width = int(size_string)\n",
    "        input_height = int(size_string)\n",
    "        input_depth = 3\n",
    "        model_file_name = os.path.join(model_dir_name, model_base_name)\n",
    "        input_mean = 127.5\n",
    "        input_std = 127.5\n",
    "    else:\n",
    "        tf.logging.error(\"Wrong architecture '%s'\", architecture)\n",
    "        raise ValueError('Wrong architecture', architecture)\n",
    "\n",
    "    return {'data_url': data_url, 'bottleneck_tensor_name': bottleneck_tensor_name, 'bottleneck_tensor_size': bottleneck_tensor_size,\n",
    "            'input_width': input_width, 'input_height': input_height, 'input_depth': input_depth, 'resized_input_tensor_name': resized_input_tensor_name,\n",
    "            'model_file_name': model_file_name, 'input_mean': input_mean, 'input_std': input_std, 'quantize_layer': is_quantized, }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja downloadModelIfNotAlreadyPresent()\n",
    "Pobranie modelu na podstawie zadanej architektury jeśli ten nie istnieje jeszcze w strukturze projektu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadModelIfNotAlreadyPresent(data_url):\n",
    "    #Pobranie modelu i jego wypakowanie jesli jeszcze nie istnieje\n",
    "    dest_directory = MODEL_DIR\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    filename = data_url.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\r>> Downloading %s %.1f%%' % (filename, float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "        filepath, _ = urllib.request.urlretrieve(data_url, filepath, _progress)\n",
    "        print()\n",
    "        statinfo = os.stat(filepath)\n",
    "        tf.logging.info('Successfully downloaded ' + str(filename) + ', statinfo.st_size = ' + str(statinfo.st_size) + ' bytes')\n",
    "        print('Extracting file from ', filepath)\n",
    "        tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
    "    else:\n",
    "        print('Model already present in disk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja create_model_graph()\n",
    "Tworzy graf modelu na podstawie informacji o modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_graph(model_info):\n",
    "    #Tworzy graf z zapisanego pliku i zwraca obiekt modelu\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        model_path = os.path.join(MODEL_DIR, model_info['model_file_name'])\n",
    "        print('Model path: ', model_path)\n",
    "        with gfile.FastGFile(model_path, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            bottleneck_tensor, resized_input_tensor = (tf.import_graph_def(graph_def, name='', return_elements=[model_info['bottleneck_tensor_name'], model_info['resized_input_tensor_name'],]))\n",
    "    return graph, bottleneck_tensor, resized_input_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja create_image_lists()\n",
    "Tworzy listy obrazów, podział obrazów na testowe, walidacyjne i uczące na podstawie zmiennych ustalanych na wejściu programu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_lists(image_dir, testing_percentage, validation_percentage):\n",
    "    #Tworzenie listy obrazow uczacych, przeszukiwanie folderow i rozdzielenie obrazow na testowe, treningowe i walidacyjne\n",
    "    #error jesli scieza nie istnieje\n",
    "    if not gfile.Exists(image_dir):\n",
    "        tf.logging.error(\"Image directory '\" + image_dir + \"' not found.\")\n",
    "        return None\n",
    "\n",
    "    result = {}\n",
    "    # lista subkategori\n",
    "    sub_dirs = [x[0] for x in gfile.Walk(image_dir)]\n",
    "    is_root_dir = True\n",
    "    for sub_dir in sub_dirs:\n",
    "        # Jeśli nie jesteśmy w ścieżce głównej (root), ustawienie pętli na 'false', aby w następnym przejściu rozpocząć pętle od początku\n",
    "        if is_root_dir:\n",
    "            is_root_dir = False\n",
    "            continue\n",
    "\n",
    "        dir_name = os.path.basename(sub_dir)\n",
    "        if dir_name == image_dir:\n",
    "            continue\n",
    "\n",
    "        extensions = ['jpg', 'jpeg']\n",
    "        file_list = []\n",
    "        tf.logging.info(\"Looking for images in '\" + dir_name + \"'\")\n",
    "        for extension in extensions:\n",
    "            file_glob = os.path.join(image_dir, dir_name, '*.' + extension)\n",
    "            file_list.extend(gfile.Glob(file_glob))\n",
    "\n",
    "        if not file_list:\n",
    "            tf.logging.warning('No files found')\n",
    "            continue\n",
    "\n",
    "        if len(file_list) < 20:\n",
    "            tf.logging.warning('WARNING: Folder has less than 20 images, which may cause issues.')\n",
    "        elif len(file_list) > MAX_NUM_IMAGES_PER_CLASS:\n",
    "            tf.logging.warning('WARNING: Folder {} has more than {} images. Some images will never be selected.'.format(dir_name, MAX_NUM_IMAGES_PER_CLASS))\n",
    "\n",
    "        label_name = re.sub(r'[^a-z0-9]+', ' ', dir_name.lower())\n",
    "        training_images = []\n",
    "        testing_images = []\n",
    "        validation_images = []\n",
    "        for file_name in file_list:\n",
    "            base_name = os.path.basename(file_name)\n",
    "            hash_name = re.sub(r'_nohash_.*$', '', file_name)\n",
    "            hash_name_hashed = hashlib.sha1(compat.as_bytes(hash_name)).hexdigest()\n",
    "            percentage_hash = ((int(hash_name_hashed, 16) % (MAX_NUM_IMAGES_PER_CLASS + 1)) * (100.0 / MAX_NUM_IMAGES_PER_CLASS))\n",
    "            if percentage_hash < validation_percentage:\n",
    "                validation_images.append(base_name)\n",
    "            elif percentage_hash < (testing_percentage + validation_percentage):\n",
    "                testing_images.append(base_name)\n",
    "            else:\n",
    "                training_images.append(base_name)\n",
    "        result[label_name] = {'dir': dir_name, 'training': training_images, 'testing': testing_images, 'validation': validation_images,}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja add_jpeg_decoding()\n",
    "Operacje dekodowania i zmiany rozmiaru obrazu na potrzeby tworzenia grafu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_jpeg_decoding(input_width, input_height, input_depth, input_mean, input_std):\n",
    "\n",
    "    jpeg_data = tf.placeholder(tf.string, name='DecodeJPGInput')\n",
    "    decoded_image = tf.image.decode_jpeg(jpeg_data, channels=input_depth)\n",
    "    decoded_image_as_float = tf.cast(decoded_image, dtype=tf.float32)\n",
    "    decoded_image_4d = tf.expand_dims(decoded_image_as_float, 0)\n",
    "    resize_shape = tf.stack([input_height, input_width])\n",
    "    resize_shape_as_int = tf.cast(resize_shape, dtype=tf.int32)\n",
    "    resized_image = tf.image.resize_bilinear(decoded_image_4d, resize_shape_as_int)\n",
    "    offset_image = tf.subtract(resized_image, input_mean)\n",
    "    mul_image = tf.multiply(offset_image, 1.0 / input_std)\n",
    "    return jpeg_data, mul_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja cache_bottlenecks()\n",
    "Zapisanie warstwy \"bottleneck\" do pliku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_bottlenecks(sess, image_lists, image_dir, bottleneck_dir, jpeg_data_tensor, decoded_image_tensor,\n",
    "                      resized_input_tensor, bottleneck_tensor, architecture):\n",
    "\n",
    "    how_many_bottlenecks = 0\n",
    "    makeDirIfDoesNotExist(bottleneck_dir)\n",
    "    for label_name, label_lists in image_lists.items():\n",
    "        for category in ['training', 'testing', 'validation']:\n",
    "            category_list = label_lists[category]\n",
    "            for index, unused_base_name in enumerate(category_list):\n",
    "                get_or_create_bottleneck(sess, image_lists, label_name, index, image_dir, category, bottleneck_dir,\n",
    "                                         jpeg_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor, architecture)\n",
    "            how_many_bottlenecks += 1\n",
    "            if how_many_bottlenecks % 100 == 0:\n",
    "                tf.logging.info(str(how_many_bottlenecks) + ' bottleneck files created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja get_or_create_bottleneck()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_bottleneck(sess, image_lists, label_name, index, image_dir, category, bottleneck_dir, jpeg_data_tensor,\n",
    "                             decoded_image_tensor, resized_input_tensor, bottleneck_tensor, architecture):\n",
    "    #Pobranie lub utworzenie warstwy \"bottleneck\"\n",
    "\n",
    "    label_lists = image_lists[label_name]\n",
    "    sub_dir = label_lists['dir']\n",
    "    sub_dir_path = os.path.join(bottleneck_dir, sub_dir)\n",
    "    makeDirIfDoesNotExist(sub_dir_path)\n",
    "    bottleneck_path = get_bottleneck_path(image_lists, label_name, index, bottleneck_dir, category, architecture)\n",
    "    if not os.path.exists(bottleneck_path):\n",
    "        create_bottleneck_file(bottleneck_path, image_lists, label_name, index, image_dir, category, sess, jpeg_data_tensor,\n",
    "                               decoded_image_tensor, resized_input_tensor, bottleneck_tensor)\n",
    "            # czytanie zawartosci jako jeden string\n",
    "    with open(bottleneck_path, 'r') as bottleneck_file:\n",
    "        bottleneckBigString = bottleneck_file.read()\n",
    "\n",
    "    bottleneckValues = []\n",
    "    errorOccurred = False\n",
    "    try:\n",
    "        # podzial odczytanych wartosci w stringu na pojedyncze typu float\n",
    "        bottleneckValues = [float(individualString) for individualString in bottleneckBigString.split(',')]\n",
    "    except ValueError:\n",
    "        tf.logging.warning('Invalid float found, recreating bottleneck')\n",
    "        errorOccurred = True\n",
    "\n",
    "    if errorOccurred:\n",
    "        # jestli blad, probje jeszcze raz utworzyc plik\n",
    "        create_bottleneck_file(bottleneck_path, image_lists, label_name, index, image_dir, category, sess,\n",
    "                               jpeg_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor)\n",
    "\n",
    "        # czytanie nowo utworzonego pliku\n",
    "        with open(bottleneck_path, 'r') as bottleneck_file:\n",
    "            bottleneckBigString = bottleneck_file.read()\n",
    "\n",
    "        bottleneckValues = [float(individualString) for individualString in bottleneckBigString.split(',')]\n",
    "    return bottleneckValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja get_bottleneck_path()\n",
    "Zwraca ścieżke do pliku \"bootleneck\" dla zadanych parametrów wejściowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bottleneck_path(image_lists, label_name, index, bottleneck_dir, category, architecture):\n",
    "    #zwrocenie sciezki do pliku\n",
    "    return get_image_path(image_lists, label_name, index, bottleneck_dir, category) + '_' + architecture + '.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja create_bottleneck_file()\n",
    "Funkcja tworzy plik na podstawie zadanych parametrów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n",
    "                           image_dir, category, sess, jpeg_data_tensor,\n",
    "                           decoded_image_tensor, resized_input_tensor,\n",
    "                           bottleneck_tensor):\n",
    "    tf.logging.info('Creating bottleneck at ' + bottleneck_path)\n",
    "    image_path = get_image_path(image_lists, label_name, index, image_dir, category)\n",
    "    if not gfile.Exists(image_path):\n",
    "        tf.logging.fatal('File does not exist %s', image_path)\n",
    "\n",
    "    image_data = gfile.FastGFile(image_path, 'rb').read()\n",
    "    try:\n",
    "        bottleneck_values = run_bottleneck_on_image(sess, image_data, jpeg_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError('Error during processing file %s (%s)' % (image_path, str(e)))\n",
    "\n",
    "    bottleneck_string = ','.join(str(x) for x in bottleneck_values)\n",
    "    with open(bottleneck_path, 'w') as bottleneck_file:\n",
    "        bottleneck_file.write(bottleneck_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja run_bottleneck_on_image()\n",
    "Przeprowadza wnioskowanie na obrazie aby wyodrębnić warstwę \"bottleneck\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bottleneck_on_image(sess, image_data, image_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor):\n",
    "\n",
    "    # dekodowanie obrazu i przeskalowanie wartosci pikseli\n",
    "    resized_input_values = sess.run(decoded_image_tensor, {image_data_tensor: image_data})\n",
    "    # Przepuszczenie obrazu przez siec\n",
    "    bottleneck_values = sess.run(bottleneck_tensor, {resized_input_tensor: resized_input_values})\n",
    "    bottleneck_values = np.squeeze(bottleneck_values)\n",
    "    return bottleneck_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja get_image_path()\n",
    "Funkcja zwraca ścieżkę do zdjęcia o zadanej etykiecie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_path(image_lists, label_name, index, image_dir, category):\n",
    "    #zwraca sciezke do konkretnego zdjecia, spelniajacego wejsciowe parametry\n",
    "    if label_name not in image_lists:\n",
    "        tf.logging.fatal('Label does not exist %s.', label_name)\n",
    "    label_lists = image_lists[label_name]\n",
    "    if category not in label_lists:\n",
    "        tf.logging.fatal('Category does not exist %s.', category)\n",
    "    category_list = label_lists[category]\n",
    "    if not category_list:\n",
    "        tf.logging.fatal('Label %s has no images in the category %s.', label_name, category)\n",
    "    mod_index = index % len(category_list)\n",
    "    base_name = category_list[mod_index]\n",
    "    sub_dir = label_lists['dir']\n",
    "    full_path = os.path.join(image_dir, sub_dir, base_name)\n",
    "    return full_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja add_final_training_ops()\n",
    "Funckja dodaje nową warstwe softmax. Dodawana jest w celu identyfikacji nowych klas (kategorii). Funkcja dodaje odpowiednie operacje do grafu wraz ze zmiennymi przechowującymi wartości wag a następnie ustawia gradienty dla propagacji wstecznej.\n",
    "Jako wejście funkcja przyjmuje:\n",
    "- class_count - liczba kategorii, które rozpoznajemy\n",
    "- final_tensor_name - nazwa (string) końcowej warstwy, która produkuje wyniki\n",
    "- bottlenck_tensor - wyjście głównego grafu CNN\n",
    "- bottleneck_tensor_size - ilość wejść do wektora bottlenck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_final_training_ops(class_count, final_tensor_name, bottleneck_tensor, bottleneck_tensor_size, quantize_layer):\n",
    "    \"\"\"\n",
    "    #DODANIE WARSTWY SOFTMAX dla trenowania\n",
    "    UStawienie warstwy bazuje na:\n",
    "    https://www.tensorflow.org/versions/master/tutorials/mnist/beginners/index.html\n",
    "    \"\"\"\n",
    "    with tf.name_scope('input'):\n",
    "        bottleneck_input = tf.placeholder_with_default(bottleneck_tensor, shape=[None, bottleneck_tensor_size], name='BottleneckInputPlaceholder')\n",
    "        ground_truth_input = tf.placeholder(tf.int64, [None], name='GroundTruthInput')\n",
    "\n",
    "    layer_name = 'final_training_ops'\n",
    "    with tf.name_scope(layer_name):\n",
    "        quantized_layer_weights = None\n",
    "        quantized_layer_biases = None\n",
    "        with tf.name_scope('weights'):\n",
    "            initial_value = tf.truncated_normal([bottleneck_tensor_size, class_count], stddev=0.001)\n",
    "            layer_weights = tf.Variable(initial_value, name='final_weights')\n",
    "\n",
    "            # komentarz do zapobiegania wyswietlenia ostrzezenia przez python\n",
    "            # noinspection PyTypeChecker\n",
    "        with tf.name_scope('biases'):\n",
    "            layer_biases = tf.Variable(tf.zeros([class_count]), name='final_biases')\n",
    "\n",
    "            # noinspection PyTypeChecker\n",
    "\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            if quantize_layer:\n",
    "                logits = tf.matmul(bottleneck_input, quantized_layer_weights) + quantized_layer_biases\n",
    "                logits = quant_ops.MovingAvgQuantize(logits, init_min=-32.0, init_max=32.0, is_training=True, num_bits=8,\n",
    "                                                     narrow_range=False, ema_decay=0.5)\n",
    "                tf.summary.histogram('pre_activations', logits)\n",
    "            else:\n",
    "                logits = tf.matmul(bottleneck_input, layer_weights) + layer_biases\n",
    "                tf.summary.histogram('pre_activations', logits)\n",
    "    final_tensor = tf.nn.softmax(logits, name=final_tensor_name)\n",
    "\n",
    "    tf.summary.histogram('activations', final_tensor)\n",
    "\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        cross_entropy_mean = tf.losses.sparse_softmax_cross_entropy(labels=ground_truth_input, logits=logits)\n",
    "\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy_mean)\n",
    "\n",
    "    with tf.name_scope('train'):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(LEARNING_RATE)\n",
    "        train_step = optimizer.minimize(cross_entropy_mean)\n",
    "    return (train_step, cross_entropy_mean, bottleneck_input, ground_truth_input, final_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja add_evaluation_step()\n",
    "Funkcja zwraca dane na temat precyzji podczas każdorazowej ewaluacji modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_evaluation_step(result_tensor, ground_truth_tensor):\n",
    "\n",
    "    #Inserts the operations we need to evaluate the accuracy of our results.\n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        with tf.name_scope('correct_prediction'):\n",
    "            prediction = tf.argmax(result_tensor, 1)\n",
    "            correct_prediction = tf.equal(prediction, ground_truth_tensor)\n",
    "        # end with\n",
    "        with tf.name_scope('accuracy'):\n",
    "            evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        # end with\n",
    "    tf.summary.scalar('accuracy', evaluation_step)\n",
    "    return evaluation_step, prediction\n",
    "# end function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja get_random_cached_bottlenecks()\n",
    "Funkcja zwaraca wartości \"bottlenecks\" dla określonej liczby zdjęć w zadanej kategorii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_cached_bottlenecks(sess, image_lists, how_many, category, bottleneck_dir, image_dir, jpeg_data_tensor,\n",
    "                                  decoded_image_tensor, resized_input_tensor, bottleneck_tensor, architecture):\n",
    "    \n",
    "    class_count = len(image_lists.keys())\n",
    "    bottlenecks = []\n",
    "    ground_truths = []\n",
    "    filenames = []\n",
    "    if how_many >= 0:\n",
    "        for unused_i in range(how_many):\n",
    "            label_index = random.randrange(class_count)\n",
    "            label_name = list(image_lists.keys())[label_index]\n",
    "            image_index = random.randrange(MAX_NUM_IMAGES_PER_CLASS + 1)\n",
    "            image_name = get_image_path(image_lists, label_name, image_index, image_dir, category)\n",
    "            bottleneck = get_or_create_bottleneck(sess, image_lists, label_name, image_index, image_dir, category, bottleneck_dir,\n",
    "                                                  jpeg_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor, architecture)\n",
    "            bottlenecks.append(bottleneck)\n",
    "            ground_truths.append(label_index)\n",
    "            filenames.append(image_name)\n",
    "    else:\n",
    "        for label_index, label_name in enumerate(image_lists.keys()):\n",
    "            for image_index, image_name in enumerate(image_lists[label_name][category]):\n",
    "                image_name = get_image_path(image_lists, label_name, image_index, image_dir, category)\n",
    "                bottleneck = get_or_create_bottleneck(sess, image_lists, label_name, image_index, image_dir, category, bottleneck_dir,\n",
    "                                                      jpeg_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor, architecture)\n",
    "                bottlenecks.append(bottleneck)\n",
    "                ground_truths.append(label_index)\n",
    "                filenames.append(image_name)\n",
    "    return bottlenecks, ground_truths, filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja save_graph_to_file()\n",
    "Funkcja zapisuje utworzony lub zmodyfikowany graf do pliku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graph_to_file(sess, graph, graph_file_name):\n",
    "    output_graph_def = graph_util.convert_variables_to_constants(sess, graph.as_graph_def(), [FINAL_TENSOR_NAME])\n",
    "    with gfile.FastGFile(graph_file_name, 'wb') as f:\n",
    "        f.write(output_graph_def.SerializeToString())\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting program . . .\n",
      "\n",
      "ERROR: TEST_IMAGES_DIR \"C:\\Users\\marci\\Documents\\ZI_Project/test_images\" does not seem to exist\n",
      "Did you set up the test images?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File: test.py\n",
    "Plik, którego zadaniem jest kategoryzacja obrazów z folderu test_images do kategorii na podstawie modelu \"przeuczonego\" w powyższym procesie.\n",
    "Plik rozpoczyna się importem odpwiednich bibliotek oraz ustawieniem stałych ścieżek do grafu oraz obrazów testowych\n",
    "\n",
    "### Funkcja main()\n",
    "Funkcja sprawdza czy odpowiednie ścieżki istnieją, pobiera listę kategorii z pliku grafu a także wczytuje informacje z grafu do odpowieniego obiektu.\n",
    "W sesji tensorflow kolejno wykonywane są: otwarcie pliku zdjęcia przy pomocy opencv i sprawdzenie poprawności rozszerzenia, zmianu formatu pliku z opencv na format obsługiwany przez tensorflow. Następnie kolejno dla tak przekonwertowanego obrazu wykonywana jest predykcja na podstawie której następuje przypisanie do konkretnej kategorii. Dla każdego obrazu wyświetlana jest dokładność predyckji a także % pewności przypisania do danej kategorii sortując od największego w dół. Każde zdjęcie wyświetlane jest poprzez opencv, nakładany jest na nie informacja o kategoryzacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "#sciezka do modelu i obrazow testowych\n",
    "RETRAINED_LABELS_TXT_FILE_LOC = os.getcwd() + \"/\" + \"retrained_labels.txt\"\n",
    "RETRAINED_GRAPH_PB_FILE_LOC = os.getcwd() + \"/\" + \"retrained_graph.pb\"\n",
    "\n",
    "TEST_IMAGES_DIR = os.getcwd() + \"/test_images\"\n",
    "\n",
    "def main():\n",
    "\n",
    "    print(\"starting program\")\n",
    "    if not checkIfNecessaryPathsAndFilesExist():\n",
    "        print(\"Wrong paths to folders\")\n",
    "        return\n",
    "\n",
    "    # pobranie listy klasyfikacji z pliku\n",
    "    classifications = []\n",
    "    for currentLine in tf.gfile.GFile(RETRAINED_LABELS_TXT_FILE_LOC):\n",
    "        classification = currentLine.rstrip()\n",
    "        classifications.append(classification)\n",
    "    print(\"classifications = \" + str(classifications))\n",
    "\n",
    "    # zaladowanie grafu\n",
    "    with tf.gfile.FastGFile(RETRAINED_GRAPH_PB_FILE_LOC, 'rb') as retrainedGraphFile:\n",
    "        # instancja obiektu grafu\n",
    "        graphDef = tf.GraphDef()\n",
    "        # Wczytanie \"wytrenowanego grafu\" do obiektu\n",
    "        graphDef.ParseFromString(retrainedGraphFile.read())\n",
    "        #imporotowanie grafu jako domyslny\n",
    "        _ = tf.import_graph_def(graphDef, name='')\n",
    "\n",
    "    # error jesli sciezka do folderu z obrazami nie prawidlowa\n",
    "    if not os.path.isdir(TEST_IMAGES_DIR):\n",
    "        print(\"bad directory\")\n",
    "        return\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        for fileName in os.listdir(TEST_IMAGES_DIR):\n",
    "            if not (fileName.lower().endswith(\".jpg\") or fileName.lower().endswith(\".jpeg\")):\n",
    "                continue\n",
    "\n",
    "            print(fileName)\n",
    "\n",
    "            #otwarcie pliku prze opencv\n",
    "            imageFileWithPath = os.path.join(TEST_IMAGES_DIR, fileName)\n",
    "            openCVImage = cv2.imread(imageFileWithPath)\n",
    "\n",
    "            if openCVImage is None:\n",
    "                print(\"unable to open \" + fileName + \" as an OpenCV image\")\n",
    "                continue\n",
    "\n",
    "            finalTensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "\n",
    "            # konwersja do obrazka zgodnego z tensorflow\n",
    "            tfImage = np.array(openCVImage)[:, :, 0:3]\n",
    "            \n",
    "            # wykonanie predykcji\n",
    "            predictions = sess.run(finalTensor, {'DecodeJpeg:0': tfImage})\n",
    "\n",
    "            # sortowanie od najbardziej zgodnych\n",
    "            sortedPredictions = predictions[0].argsort()[-len(predictions[0]):][::-1]\n",
    "\n",
    "            onMostLikelyPrediction = True\n",
    "            #wykonanie dla kazdej predykcji\n",
    "            for prediction in sortedPredictions:\n",
    "                strClassification = classifications[prediction]\n",
    "\n",
    "                confidence = predictions[0][prediction] #dokladnosc predykcji zaokraglona do dwoch miejsc\n",
    "\n",
    "                if onMostLikelyPrediction:\n",
    "                    scoreAsAPercent = confidence * 100.0\n",
    "                    # przypisanie obiektu do kategori wraz z procentem pewnosci, pokazanie obrazu\n",
    "                    print(\"it appears to be a flag of \\n\" + strClassification + \", \" + \"{0:.2f}\".format(scoreAsAPercent) + \"% confidence\")\n",
    "                    writeResultOnImage(openCVImage, strClassification, \"{0:.2f}\".format(scoreAsAPercent) + \"%\")\n",
    "                    cv2.imshow(fileName, openCVImage)\n",
    "                    onMostLikelyPrediction = False\n",
    "\n",
    "                #pewnosc predykcji\n",
    "                print(strClassification + \" (\" +  \"{0:.5f}\".format(confidence) + \")\")\n",
    "\n",
    "            cv2.waitKey()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "    # zapisanie grafu do pliku\n",
    "    tfFileWriter = tf.summary.FileWriter(os.getcwd())\n",
    "    tfFileWriter.add_graph(sess.graph)\n",
    "    tfFileWriter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja checkIfNecessaryPathsAndFilesExist()\n",
    "Funckja sprawdza istnienie wszystkich potrzebnych ścieżek, jeśli nie są określone - kończy program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIfNecessaryPathsAndFilesExist():\n",
    "    if not os.path.exists(TEST_IMAGES_DIR):\n",
    "        print('')\n",
    "        print('ERROR: TEST_IMAGES_DIR \"' + TEST_IMAGES_DIR + '\" does not seem to exist')\n",
    "        print('Did you set up the test images?')\n",
    "        print('')\n",
    "        return False\n",
    "\n",
    "    if not os.path.exists(RETRAINED_LABELS_TXT_FILE_LOC):\n",
    "        print('ERROR: RETRAINED_LABELS_TXT_FILE_LOC \"' + RETRAINED_LABELS_TXT_FILE_LOC + '\" does not seem to exist')\n",
    "        return False\n",
    "\n",
    "    if not os.path.exists(RETRAINED_GRAPH_PB_FILE_LOC):\n",
    "        print('ERROR: RETRAINED_GRAPH_PB_FILE_LOC \"' + RETRAINED_GRAPH_PB_FILE_LOC + '\" does not seem to exist')\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja writeResultOnImage()\n",
    "Funkcja wypisuje informacje na obrazie wyświetlanym przez opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wypisanie danych na zdjeciu, okreslenie czecionki\n",
    "def writeResultOnImage(openCVImage, flag, confidence):\n",
    "\n",
    "    imageHeight, imageWidth, sceneNumChannels = openCVImage.shape\n",
    "\n",
    "    fontFace = cv2.FONT_HERSHEY_TRIPLEX\n",
    "\n",
    "    fontScale = 1.0\n",
    "    fontThickness = 2\n",
    "\n",
    "    fontThickness = int(fontThickness) # czcionka musi byc \"integer\", wywala inaczej opencv\n",
    "\n",
    "    upperLeftTextOriginX = int(imageWidth * 0.05)\n",
    "    upperLeftTextOriginY = int(imageHeight * 0.05)\n",
    "\n",
    "    textSize, baseline = cv2.getTextSize(resultText, fontFace, fontScale, fontThickness)\n",
    "    textSizeWidth, textSizeHeight = textSize\n",
    "\n",
    "    lowerLeftTextOriginX = upperLeftTextOriginX\n",
    "    lowerLeftTextOriginY = upperLeftTextOriginY + textSizeHeight\n",
    "    COLOUR = (255.0, 0.0, 0.0)\n",
    "    cv2.putText(openCVImage, flag, (lowerLeftTextOriginX, lowerLeftTextOriginY), fontFace, fontScale, COLOUR, fontThickness)\n",
    "    cv2.putText(openCVImage, confidence, (lowerLeftTextOriginX, int(imageHeight * 0.5)), fontFace, fontScale, COLOUR, fontThickness)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting program\n",
      "classifications = ['austria flag', 'belarus flag', 'belgium flag', 'canada flag', 'finland flag', 'france flag', 'germany flag', 'greece flag', 'irland flag', 'lithuania flag', 'nederlands flag', 'poland flag', 'portugal flag', 'russia flag', 'serbia flag', 'spain flag', 'sweden flag', 'ukraine flag', 'uk flag', 'usa flag']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "NodeDef mentions attr 'Truncate' not in Op<name=Cast; signature=x:SrcT -> y:DstT; attr=SrcT:type; attr=DstT:type>; NodeDef: Cast = Cast[DstT=DT_FLOAT, SrcT=DT_UINT8, Truncate=false](DecodeJpeg). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\ZI_Project\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\u001b[0m in \u001b[0;36mimport_graph_def\u001b[1;34m(graph_def, input_map, return_elements, name, op_dict, producer_op_list)\u001b[0m\n\u001b[0;32m    417\u001b[0m         results = c_api.TF_GraphImportGraphDefWithResults(\n\u001b[1;32m--> 418\u001b[1;33m             graph._c_graph, serialized, options)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    419\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mScopedTFImportGraphDefResults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: NodeDef mentions attr 'Truncate' not in Op<name=Cast; signature=x:SrcT -> y:DstT; attr=SrcT:type; attr=DstT:type>; NodeDef: Cast = Cast[DstT=DT_FLOAT, SrcT=DT_UINT8, Truncate=false](DecodeJpeg). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-972361fa1b80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-7eec8652fb42>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mgraphDef\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretrainedGraphFile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;31m#imporotowanie grafu jako domyslny\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_graph_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraphDef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# error jesli sciezka do folderu z obrazami nie prawidlowa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ZI_Project\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m                 instructions)\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    456\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ZI_Project\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\u001b[0m in \u001b[0;36mimport_graph_def\u001b[1;34m(graph_def, input_map, return_elements, name, op_dict, producer_op_list)\u001b[0m\n\u001b[0;32m    420\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m         \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[1;31m# Create _DefinedFunctions for any imported functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: NodeDef mentions attr 'Truncate' not in Op<name=Cast; signature=x:SrcT -> y:DstT; attr=SrcT:type; attr=DstT:type>; NodeDef: Cast = Cast[DstT=DT_FLOAT, SrcT=DT_UINT8, Truncate=false](DecodeJpeg). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.)."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ZI_Project",
   "language": "python",
   "name": "zi_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
